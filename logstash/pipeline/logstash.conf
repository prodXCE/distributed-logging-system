# logstash/pipeline/logstash.conf

# ================= INPUT =================
input {
  kafka {
    bootstrap_servers => "kafka:29092"
    topics => ["logs-topic"]
    group_id => "logstash-consumer-group"

    # CORRECT: Only one codec is allowed. Since our Spring app sends JSON,
    # this is the only one we need. It will parse the entire message from Kafka.
    codec => "json"
  }
}

# ================= FILTER =================
filter {
  # The 'json' codec in the input has already parsed the message from Kafka.
  # Now we have fields like 'rawMessage', 'source', 'level', etc.

  # --- SCENARIO 1: Key-Value Business Log ---
  # If the rawMessage contains 'transactionId=', we treat it as a key-value log.
  if "transactionId=" in [rawMessage] {
    kv {
      source => "rawMessage"
      field_split => " "
      value_split => "="
      # We don't remove the original message field, in case parsing fails on some part.
    }
  }

  # --- SCENARIO 2: Standard Application Log (including first line of stack traces) ---
  # Otherwise, if the message starts with a standard log level...
  else if [rawMessage] =~ "(?m)^(INFO|WARN|ERROR|DEBUG)" {
    # We use the 'grok' filter, which uses powerful regex-like patterns.
    # The (?m) flag allows ^ to match the beginning of any line, useful for multiline rawMessage.
    grok {
      match => { "rawMessage" => "(?m)^%{LOGLEVEL:level_parsed} \[%{DATA:thread_name}\] %{JAVACLASS:class_name} - %{GREEDYDATA:message_parsed}" }

      # Overwrite the original 'level' and 'message' fields with the more accurate
      # ones we just parsed.
      overwrite => ["level", "message"]
    }
  }

  # --- TIMESTAMP CORRECTION ---
  # The 'date' filter parses a timestamp from a field and uses it as the
  # official timestamp for the event (@timestamp).
  date {
    match => [ "timestamp", "ISO8601" ]
    remove_field => ["timestamp"]
  }

  # --- CLEANUP ---
  # The mutate filter can add, remove, or change fields.
  mutate {
    # Let's keep the rawMessage for now for easier debugging in Kibana.
    # remove_field => ["rawMessage"]
  }
}

# ================= OUTPUT =================
output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logs-%{+YYYY.MM.dd}"
  }

  # For debugging, print every processed event to the Logstash console.
  stdout {
    codec => rubydebug
  }
}
